### 2022.12.02
* regime: 영역, 특정한 상황 또는 규칙
> <font size=1>It outperforms fully supervised ImageNet models and increases robustness in small data <span style="color: orange;">regimes</span>, reducing annotation cost across mul- tiple medical imaging applications.</font>

* synergistic effects: 시너지 효과
> <font size=1>Existing efforts, however, omit their <span style="color: orange;">synergistic effects</span> on each other in a ternary setup.</font>

* foster: 기르다, 육성하다
> <font size=1>Can discriminative, restora- tive, and adversarial learning be seamlessly integrated into a single framework to <span style="color: orange;">foster</span> collaborative learning for deep semantic representation.</font>

* glean: 줍다, 수집하다
> <font size=1>We have designed a novel self-supervised learning framework, called DiRA, by uniting discriminative learning, restorative learning, and adversarial learning in a unified manner to <span style="color: orange;">glean</span> complementary visual information from unlabeled medical im ages.</font>

* leverage: (이점을 최대화하기 위해 어떤 것을) 활용하다, 사용하다 
> <font size=1>Our restorative learning branch aims to enhance discrimination learning by <span style="color: orange;">leveraging</span> fine-grained visual information. </font>

### 2022.12.01
* deformation: 변형
> <font size=1>Good representation in fine-grained classification should be invariant to the <span style="color: orange;">deformations</span> of object parts and the changes of viewing angles.</font>

* devote to: ~에 전념하다
> <font size=1>A large number of deep approaches were <span style="color: orange;">devoted to</span> the former challenge of capturing finegrained details in local regions.</font>

* besides: 게다가, 이외에도, 뿐만 아니라
> <font size=1><span style="color: orange;">Besides</span>, we also measure the compactness of image representations.</font>

### 2022.11.30
* subordinate: 종속적인, 아래의, 하위의
> <font size=1>The problem of classifying fine-grained objects is made more challenging due to the inherently subtle shape difference across the <span style="color: orange;">subordinate</span> categories.</font>

* non-trivial: 사소하지 않은, 중요한, 어려운
> <font size=1>Learning a discriminative representation for fine-grained objects remains <span style="color: orange;">non-trivial</span> in the context of deep learning.</font>

### 2022.11.28
* counterpart: 상대방, 대응물
> <font size=1>Each model can thus benefit from its <span style="color: orange;">counterpart</span> by utilizing cross-model predictions as supervision.</font>

* to this end: 이를 위해
> <font size=1>We want to save the building. <span style="color: orange;">To this end</span>, we have hired someone to assess its current state.</font>

* to the best of our knowledge: 우리가 아는 한
> <font size=1><span style="color: orange;">To the best of our knowledge</span>, that design will not work.</font>

* in particular: 특히
> <font size=1><span style="color: orange;">In particular</span>, it better captures temporal dynamics in recognizing actions.</font>

* empirical analysis: 실증적 분석, 실험을 통해 증명하는 분석
> <font size=1>We also conduct a comprehensive <span style="color: orange;">empirical analysis</span> to study how the cross-model supervision helps improve performance.</font>

* incentivize: 장려하다, 어떤 일을 하도록 유도하다
> <font size=1>This symmetric design <span style="color: orange;">incentivizes</span> the two models to learn complementary representations.</font>

*  auxiliary: 보조, 보조적인 (assistant)
> <font size=1>The primary backbone is supplemented by a lightweight <span style="color: orange;">auxiliary</span> network with a different structure and fewer channels than the backbone.</font>

* among: ~중에
> <font size=1><span style="color: orange;">Among</span> two strategies, task-dynamic feature alignment methods are being spotlighted.</font>