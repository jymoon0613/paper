# Gather-Excite: Exploiting Feature Context in Convolutional Neural Networks (NIPS, 2018)

[논문링크](https://proceedings.neurips.cc/paper/2018/hash/dc363817786ff182b7bc59565d864523-Abstract.html)

<p align="center">
    <img width="600" alt='fig1' src="./img/01_21_01.png?raw=true"></br>
    <em><font size=2>Overall Architecture</font></em>
</p>

## 연구목적
- CNN에서 context 정보를 추출하는 것은 성능 향상에 중요함
- 대표적으로 SE-Net은 feature channels를 reweighting하는 방식으로 분류 성능을 개선하였음
> - SE-Net의 squeeze operator가 context aggregator의 역할을 수행함
- 본 논문은 context 정보가 네트워크 전반에 걸쳐 활용될 수 있도록 두 가지 operators로 구성된 context modules를 설계함
> - Gather operator: feature maps에서 conext 정보를 수집
> - Excite operator: 수집된 context 정보에 기반하여 feature maps를 변형

## 접근법
- Gather operator(G)는 input feature map의 각 channel 마다 정의된 spatial 범위(spatial extent)에 기반하여 값을 aggregate함
- Excite operator(E)는 gather operator의 결과값을 바탕으로 input feature map을 rescaling함
- GE를 learnable parameters 없이 디자인할 수 있음
> - G: average poolng, E: interpolation 및 sigmoid function
> - Parameter-free 디자인으로도 성능 향상을 기록하였으며 이는 context 정보와 그것을 모델링할 수 있는 module의 중요성을 보여줌
- 다음으로 parameters를 사용하는 GE를 디자인함
> - G: depth-wise convolution, E: parameter-free의 E와 동일
> - Parameters를 추가했을 때 parameter-free보다 더 성능이 향상되었음
> - 네트워크의 모든 stage에서 GE를 사용했을 때 성능이 가장 좋았음
- E를 SE-Net과 유사하게 1x1 convolutional channel subnetwork 구조로 구성하였을 때 성능이 더 향상되었음

## 실험결과
- GE의 추가는 residual networks(i.e., ResNet, WRN) 및 lightweight networks(i.e., ShuffleNet)의 성능을 향상시킴
- 또한, GE의 추가는 object detection 성능도 향상시킴

## 의견
- /