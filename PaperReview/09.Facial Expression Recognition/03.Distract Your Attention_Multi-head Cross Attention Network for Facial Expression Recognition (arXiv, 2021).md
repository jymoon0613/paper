# Distract Your Attention: Multi-head Cross Attention Network for Facial Expression Recognition (arXiv, 2021)

[논문 링크](https://arxiv.org/abs/2109.07270)

<p align="center">
    <img width="600" alt='fig1' src="./img/09_03_01.png?raw=true"></br>
    <em><font size=2>Overall Architecture</font></em>
</p>

## 연구목적
- 일반적인 이미지 분류 태스크와는 달리, 표정 클래스 간에는 공통성이 강하게 나타남 
(여러 표정은 본질적으로 유사한 기본 얼굴 모양을 공유하며 그 차이는 구별하기 힘들 수 있음)
(어려운 태스크) 
- 이러한 문제를 해결하기 위해 Loss Function에 Center Loss 추가하여 Intra-class Variance를 감소시켜 (Class에 속하는 샘플들을 Class Center와 가깝게 위치하도록) 클래스 구분을 증진시킬 수 있음 
- 또한, Attention Mechanism을 통해 미세한 지역적 차이를 잡아내는 방법도 고안되었지만, 하나의 Attention Head를 사용하는 것은 얼굴 표정의 여러 중요한 부분을 모두 잡아내지 못한다는 문제가 있음 
- 본 연구에서는 Center Loss의 개념을 확장시킨 Feature Clustering Network (FCN)을 도입하여 Intra-class Variation 및 Inter-class Margins를 최적화하고자 함. 또한, 얼굴 표정의 여러 부분에 집중하기 위한 Multi-head Cross Attention Network (MAN)과 추출된 피처의 통합을 위한 Attention Fusion Network (AFN)을 도입하여 FER 성능을 개선하고자 함 

## 접근법
### (1) Feature Clustering Network (FCN) – Affinity Loss 
- Inter-class Margins을 최대화하기 위해 Discriminative Loss 중 하나인 Affinity Loss를 사용 
- 학습시마다 각 클래스의 피처는 클래스의 중심으로 이동하고, 서로 다른 클래스의 중심은 점점 멀어짐 
- Backbone Network는 Affinity Loss를 사용하는 FCN이며, 모델은 입력 피처에 대해 변형된 피처를 아웃풋으로 산출함 
### (2) Multi-head Cross Attention Network (MAN) 
- 다수의 Parallel Cross Attention Heads로 구성됨 
- Cross Attention Head는 Spatial Attention Unit과 Channel Attention Unit의 조합임 
- Spatial Attention Unit은 FCN에서 추출된 피처에서 Spatial Features를 추출 
- Channel Attention Unit은 추출된 Spatial Features에서 Channel Features를 추출 
- MAN을 통해 입력 표정 이미지의 다양한 지역적 피처를 추출할 수 있음 
### (3) Attention Fusion Network (AFN) 
- MAN을 통해 여러 지역적 피처를 추출했지만 그 중요도의 순서는 알지 못함 
- AFN은 Log-softmax 함수를 통해 Attention Maps의 스케일링 함으로써 가장 집중해야 할 부분을 강조함 
- Spatial Attention Unit은 FCN에서 추출된 피처에서 Spatial Features를 추출 
- Channel Attention Unit은 추출된 Spatial Features에서 Channel Features를 추출 

## 실험결과
- AffectNet-8, AffectNet-7에서 모두 SOTA 성능 기록 
- RAF-DB에서도 SOTA 성능 기록 

## 의견
- 성능을 더욱 개선시킬 방법은? 
- 네트워크가 매우 복잡함 