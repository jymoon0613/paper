# Attention Mechanism-based CNN for Facial Expression Recognition (Neurocomputing, 2020)

[논문 링크](https://www.sciencedirect.com/science/article/pii/S0925231220309838)

<p align="center">
    <img width="600" alt='fig1' src="./img/09_09_01.png?raw=true"></br>
    <em><font size=2>Overall Architecture</font></em>
</p>

## 연구목적
- FER은 여러 어플리케이션에 적용될 수 있는 중요한 주제임 
- 표정의 복잡성, 다양성, 환경 노이즈 때문에 FER의 성능은 불만족스러운 현황임 
- FER을 위해 사용할 수 있는 피처는 눈, 코, 입과 같은 얼굴 피처와 얼굴을 모델링할 수 있는 얼굴 모델 피처가 있음 
- 즉, 이러한 두 피처의 혼합 방식으로 전체적인 얼굴 표현을 얻거나, 특정 지점을 지역적으로 표현하는 방식으로 해당 표정이 속하는 클래스를 예측할 수 있음 
- 또한 Attention Mechanism은 입력 이미지의 유용한 부분에 집중하도록 함으로써 분류 성능 개선에 긍정적인 영향을 줄 수 있음 
- 따라서, 본 연구에서는 Attention Mechanism이 포함된 CNN을 설계함으로써 FER 성능을 개선하고자 함 

## 접근법
### (1) Network Architecture 
- 모델은 Feature Extraction Module에서 원본 이미지와, LBP Feature Map에서 각각 피처를 추출 
- VGG16의 Convolution Layer들을 Feature Extraction Module의 Backbone으로 사용 
- 원본 이미지와 LBP 피처를 결합하고, 이로부터 Attention Mask을 생성 
- Attention Mask과 원본 이미지의 피처를 사용하여 Attention 수행 
- 이후 Reconstruction Module에서 생성된 Attention Map에 Dilated Convolution을 적용하여 다시 피처를 정제함 
- 이후 FC Layers를 거쳐 분류 수행 
### (2) Attention Mechanism 
- Residual Attention Mechanism과 마찬가지로 Attention Module은 Trunk Branch와 Mask Branch로 구분 
- Trunk Branch의 Output과 Mask Branch의 Output을 통해 Attention 수행 
### (3) Local Binary Patterns (LBP)
- 이미지의 질감 표현 및 얼굴 인식 등에 활용되는 아주 간단하면서도 효율적인 방법 
- 지역적인 이진 패턴을 계산
- 중심에 위치하는 픽셀과 이웃하는 픽셀끼리 크기를 비교하여 이웃하는 픽셀이 더 크거나 같으면 1, 아니면 0으로 처리함 
- Circle LBP는 사각형의 셀 대신에 원형의 셀을 사용
- Uniform LBP는 패턴 분석을 통해 계산 복잡도를 줄임 
- LBP는 FER에 유용한 정보들을 반영하고 있음 (이미지 간의 작은 차이들을 포착하기 쉬움) 
- 또한, LBP는 Rotation 및 Grey-scale Invariance를 지니고 있어 강건한 피처 추출이 가능 
### (4) Data Augmentation 
- 사용할 수 있는 데이터의 양이 한정적이기 때문에 오버피팅이 발생할 가능성이 높음 
- Label-preserving Transformation을 사용하여 데이터셋의 크기를 증가시킴 

## 실험결과
- 여러 FER 데이터셋에서 평가함 (CK+, JAFFE, Oulu-CASIA, FER2013, NCUFE) 
- LBP의 종류를 평가한 결과 Circle LBP를 사용할 때 성능이 가장 좋았음 
- 모델의 여러 Module에 대한 평가 결과, 제안된 네트워크의 모듈을 모두 사용하는 것이 가장 좋았음 
- 최적의 Dilation Rate의 조합도 찾음 
- 여러 데이터셋에서 좋은 성능을 기록 

## 의견
- AffectNet과 같은 Wild 데이터셋에 대한 평가가 부족함 
- LBP를 사용하는 것을 고려 
- LBP를 이용한 Self-supervised Learning Task? 
