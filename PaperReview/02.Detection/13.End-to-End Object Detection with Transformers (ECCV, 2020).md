# End-to-End Object Detection with Transformers (ECCV, 2020)

[논문링크](https://arxiv.org/abs/2005.12872)

<p align="center">
    <img width="600" alt='fig1' src="./img/02_13_01.png?raw=true"></br>
    <em><font size=2>Overall Architecture</font></em>
</p>

## 연구목적
- 본 논문에서는 NMS, anchor generation 과정을 제거한 단순화된 end-to-end detection pipeline을 제안함 (Detectio Transformer, DETR)
- 방법의 핵심은 object detection을 하나의 direct set prediction 과정으로 생각하는 것
> - Transformer 기반의 encoder-decoder 구조 적용
> - set 기반의 global loss 적용 (bipartite matching 기반)

## 접근법
### (1) Object Detection Set Prediction Loss
- DETR은 decoder를 통해 N개의 예측을 수행함 (ground-truth objects 보다 많은 수를 예측)
- 예측된 objects를 ground-truth와 어떻게 비교할 것인지가 어려운 문제임
- DETR은 예측된 objects와 ground-truth objects 간의 optimal한 bipartite matching을 생성하고 object-specific한 loss를 optimize함
- Ground-truth objects의 수를 'no object'로 padding하여 N과 맞춰줌
- Hungarian algorithm을 통해 하나의 예측 object와 matching cost가 가장 작은 ground-truth object를 매칭함 (predicted objects마다 unique한 ground-truth가 매칭 (bipartite matching))
- Matching cost는 class prediction과 boxes 간의 유사도를 모두 고려함
- 이러한 Bipartite matching은 이전의 NMS 및 anchor generation을 대체할 수 있음
- Matching을 수행한 다음 각각의 pair에 대해 이전의 detection loss와 유사한 hungarian loss를 계산
### (2) DETR architecture
- DETR은 매우 간단한 구조로 구성됨: dense feature 추출을 위한 CNN backbone, encoder-decoder Transformer, 최종 예측을 위한 feed forward network (FFN)
- Backbone은 입력 이미지로부터 feature maps를 추출
- Output feature map을 1x1 convolution으로 channel을 줄이고, Transformer encoder의 sequence 입력으로 사용하기 위해 spatial dimension을 1차원으로 축소 (HxWxd -> HWxd)
- Encoder의 각 attention layer에서 fixed positional encoding을 사용함 
- Decoder는 기존 Transformer decoder block을 사용하되, 기존의 decoder가 한 번에 하나의 output element를 예측하는 것과 달리 각 decoder block은 모든 N개의 예측을 동시에 처리함
- 또한, decoder에서도 object queries로 불리는 positional encoding 값을 각 attention layer에서 더해줌
- 3-layer MLP로 구성된 FFN에서 box coordinates와 class label 예측이 수행됨
- 학습 시 각 class 별로 예측되는 objects의 수를 조정하기 위해 각 decoder마다 같은 가중치를 공유하는 예측 FFN과 hungarian loss를 배치 (auxiliary decoding losses)

## 실험결과
- MS COCO 벤치마크에서 Faster R-CNN과 견줄만한 성능 달성
- 연산량 측면에서 보면 DETR이, FPS에서는 Faster R-CNN이 좋은 성능을 보임
- 인코더의 layer수가 늘어날 수록 성능이 증가
- 또한 DETR은 panoptic segmentation task에서도 좋은 성능을 보임 (versatile and extensible한 모델임을 증명)
- Encoder의 attention은 이미지 수준의 global한 attention을 통해 object instance를 분리하는 반면, decoder의 attention은 보다 지역적인 attention (head, legs) 등에 집중하여 object의 경계를 추론함

## 의견
- /